{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import json\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_and_adjectives(text):\n",
    "\n",
    "    annotated_text = nlp.annotate(text, properties={\n",
    "        'annotators': 'tokenize,ssplit,pos,lemma,ner',  # POS tagging, Lemmatization, NER\n",
    "        'outputFormat': 'json'\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        annotated_json = json.loads(annotated_text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing the JSON response: {e}\")\n",
    "        return {}\n",
    "\n",
    "    entities = {}\n",
    "\n",
    "    for sentence in annotated_json.get('sentences', []):\n",
    "        sentence_adjectives = set() \n",
    "        sentence_names = set() \n",
    "\n",
    "        for word in sentence.get('tokens', []):\n",
    "            word_text = word.get('word')\n",
    "            pos_tag = word.get('pos')\n",
    "            ner_tag = word.get('ner')\n",
    "\n",
    "            if ner_tag == 'PERSON':\n",
    "                sentence_names.add(word_text)\n",
    "\n",
    "            if pos_tag and pos_tag.startswith('JJ'):  # Adjective tags like JJ, JJR, JJS\n",
    "                sentence_adjectives.add(word_text)\n",
    "\n",
    "       \n",
    "        for name in sentence_names:\n",
    "            if name not in entities:\n",
    "                entities[name] = set()\n",
    "            \n",
    "            entities[name].update(sentence_adjectives)\n",
    "\n",
    "    return entities\n",
    "\n",
    "def extract_entities_and_adjectives_related(text):\n",
    "    annotated_text = nlp.annotate(text, properties={\n",
    "        'annotators': 'tokenize,ssplit,pos,lemma,ner,depparse', \n",
    "        'outputFormat': 'json'\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        annotated_json = json.loads(annotated_text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing the JSON response: {e}\")\n",
    "        return {}\n",
    "\n",
    "    entities = {}\n",
    "\n",
    "    for sentence in annotated_json.get('sentences', []):\n",
    "        sentence_adjectives = {}  \n",
    "        sentence_names = set()\n",
    "\n",
    "        for word in sentence.get('tokens', []):\n",
    "            word_text = word.get('word')\n",
    "            pos_tag = word.get('pos')\n",
    "            ner_tag = word.get('ner')\n",
    "\n",
    "            if ner_tag == 'PERSON':\n",
    "                sentence_names.add(word_text)\n",
    "\n",
    "        for dep in sentence.get('enhancedPlusPlusDependencies', []):\n",
    "            gov_index = dep.get('governor') - 1  # 1-based to 0-based index\n",
    "            dep_index = dep.get('dependent') - 1\n",
    "            dep_relation = dep.get('dep')\n",
    "\n",
    "            governor_word = sentence['tokens'][gov_index]['word']\n",
    "            dependent_word = sentence['tokens'][dep_index]['word']\n",
    "\n",
    "            if dep_relation == 'amod':\n",
    "                for name in sentence_names:\n",
    "\n",
    "                    if governor_word == name or dependent_word == name:\n",
    "                        if name not in sentence_adjectives:\n",
    "                            sentence_adjectives[name] = set()\n",
    "\n",
    "                        sentence_adjectives[name].add(dependent_word)\n",
    "\n",
    "        for name in sentence_names:\n",
    "            if name not in entities:\n",
    "                entities[name] = set()\n",
    "            \n",
    "            if name in sentence_adjectives:\n",
    "                entities[name].update(sentence_adjectives[name])\n",
    "\n",
    "    return entities\n",
    "\n",
    "def extract_entities_and_adjectives_and_verbs_with_coref(text):\n",
    "\n",
    "    annotated_text = nlp.annotate(text, properties={\n",
    "        'annotators': 'tokenize,ssplit,pos,lemma,ner,depparse,coref',\n",
    "        'outputFormat': 'json'\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        annotated_json = json.loads(annotated_text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing the JSON response: {e}\")\n",
    "        return {}\n",
    "\n",
    "    entities = {}\n",
    "\n",
    "    coref_persons = {}\n",
    "    coreferences = annotated_json.get('corefs', {})\n",
    "\n",
    "    for coref_id, mentions in coreferences.items():\n",
    "        main_person_name = None\n",
    "\n",
    "        for mention in mentions:\n",
    "            sentence_index = mention['sentNum'] - 1\n",
    "            token_start = mention['startIndex'] - 1\n",
    "            token_end = mention['endIndex'] - 1\n",
    "            tokens = annotated_json['sentences'][sentence_index]['tokens'][token_start:token_end]\n",
    "\n",
    "            person_tokens = [token for token in tokens if token['ner'] == 'PERSON']\n",
    "            if person_tokens:\n",
    "                proper_names = [\n",
    "                    token['word'] for token in person_tokens if token['pos'] in ['NNP', 'NNPS']\n",
    "                ]\n",
    "                if proper_names:\n",
    "                    main_person_name = \" \".join(proper_names)\n",
    "                    break\n",
    "\n",
    "        if main_person_name:\n",
    "            for mention in mentions:\n",
    "                sentence_index = mention['sentNum'] - 1\n",
    "                token_start = mention['startIndex'] - 1\n",
    "                token_end = mention['endIndex'] - 1\n",
    "                tokens = annotated_json['sentences'][sentence_index]['tokens'][token_start:token_end]\n",
    "                mention_text = \" \".join(token['word'] for token in tokens)\n",
    "\n",
    "                coref_persons[mention_text] = main_person_name\n",
    "    for sentence_index, sentence in enumerate(annotated_json.get('sentences', [])):\n",
    "\n",
    "        for dep in sentence.get('enhancedPlusPlusDependencies', []):\n",
    "            gov_index = dep.get('governor') - 1  # 1-based to 0-based index\n",
    "            dep_index = dep.get('dependent') - 1\n",
    "            dep_relation = dep.get('dep')\n",
    "\n",
    "            governor_word = sentence['tokens'][gov_index]['word']\n",
    "            dependent_word = sentence['tokens'][dep_index]['word']\n",
    "\n",
    "            if dep_relation == 'amod' and governor_word in coref_persons:\n",
    "                linked_entity = coref_persons[governor_word]\n",
    "\n",
    "                if linked_entity:\n",
    "                    if linked_entity not in entities:\n",
    "                        entities[linked_entity] = set()\n",
    "                    entities[linked_entity].add(dependent_word)\n",
    "\n",
    "            elif dep_relation in ['cop', 'nsubj', 'xcomp', 'acl'] and dependent_word in coref_persons:\n",
    "                linked_entity = coref_persons[dependent_word]\n",
    "\n",
    "                if linked_entity:\n",
    "                    if linked_entity not in entities:\n",
    "                        entities[linked_entity] = set()\n",
    "                    entities[linked_entity].add(governor_word)\n",
    "\n",
    "    return entities\n",
    "\n",
    "def extract_entities_and_adjectives_with_corefV2(text):\n",
    "    annotated_text = nlp.annotate(text, properties={\n",
    "        'annotators': 'tokenize,ssplit,pos,lemma,ner,depparse,coref',\n",
    "        'outputFormat': 'json'\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        annotated_json = json.loads(annotated_text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing the JSON response: {e}\")\n",
    "        return {}\n",
    "\n",
    "    entities = {}\n",
    "\n",
    "    coref_persons = {}\n",
    "    coreferences = annotated_json.get('corefs', {})\n",
    "\n",
    "    for sentence_index, sentence in enumerate(annotated_json.get('sentences', [])):\n",
    "        for token in sentence.get('tokens', []):\n",
    "            if token['ner'] == 'PERSON':\n",
    "                person_name = token['word']\n",
    "                if person_name not in coref_persons:\n",
    "                    coref_persons[person_name] = person_name\n",
    "\n",
    "    for coref_id, mentions in coreferences.items():\n",
    "        main_person_name = None\n",
    "\n",
    "        for mention in mentions:\n",
    "            sentence_index = mention['sentNum'] - 1\n",
    "            token_start = mention['startIndex'] - 1\n",
    "            token_end = mention['endIndex'] - 1\n",
    "            tokens = annotated_json['sentences'][sentence_index]['tokens'][token_start:token_end]\n",
    "\n",
    "            person_tokens = [token for token in tokens if token['ner'] == 'PERSON']\n",
    "            if person_tokens:\n",
    "                proper_names = [\n",
    "                    token['word'] for token in person_tokens if token['pos'] in ['NNP', 'NNPS']\n",
    "                ]\n",
    "                if proper_names:\n",
    "                    main_person_name = \" \".join(proper_names)\n",
    "                    break\n",
    "\n",
    "        if main_person_name:\n",
    "            for mention in mentions:\n",
    "                sentence_index = mention['sentNum'] - 1\n",
    "                token_start = mention['startIndex'] - 1\n",
    "                token_end = mention['endIndex'] - 1\n",
    "                tokens = annotated_json['sentences'][sentence_index]['tokens'][token_start:token_end]\n",
    "                mention_text = \" \".join(token['word'] for token in tokens)\n",
    "\n",
    "                coref_persons[mention_text] = main_person_name\n",
    "\n",
    "    for sentence_index, sentence in enumerate(annotated_json.get('sentences', [])):\n",
    "        # Use dependency parsing to find adjective, noun, and verb modifiers\n",
    "        for dep in sentence.get('enhancedPlusPlusDependencies', []):\n",
    "            gov_index = dep.get('governor') - 1  # 1-based to 0-based index\n",
    "            dep_index = dep.get('dependent') - 1\n",
    "            dep_relation = dep.get('dep')\n",
    "\n",
    "            governor_word = sentence['tokens'][gov_index]['word']\n",
    "            dependent_word = sentence['tokens'][dep_index]['word']\n",
    "            governor_pos = sentence['tokens'][gov_index]['pos']\n",
    "            dependent_pos = sentence['tokens'][dep_index]['pos']\n",
    "\n",
    "            # Initialize linked_entity as None\n",
    "            linked_entity = None\n",
    "\n",
    "            # Check if the dependency is 'amod' a PERSON is mentionned or coref\n",
    "            if dep_relation == 'amod' and governor_word in coref_persons:\n",
    "                linked_entity = coref_persons[governor_word]\n",
    "                if linked_entity:\n",
    "                    if linked_entity not in entities:\n",
    "                        entities[linked_entity] = set()\n",
    "                    entities[linked_entity].add(dependent_word)\n",
    "\n",
    "            # Check if the relation is a verb or adjective linked to a PERSON entity\n",
    "            elif dep_relation in ['cop', 'nsubj', 'xcomp', 'acl'] and dependent_word in coref_persons:\n",
    "                linked_entity = coref_persons[dependent_word]\n",
    "                if linked_entity:\n",
    "                    if linked_entity not in entities:\n",
    "                        entities[linked_entity] = set()\n",
    "                    entities[linked_entity].add(governor_word)\n",
    "\n",
    "            # Check if the relation is a noun linked to a PERSON entity\n",
    "            elif dep_relation in ['nsubj', 'dobj', 'iobj'] and (governor_pos.startswith('NN') or dependent_pos.startswith('NN')):\n",
    "                if governor_word in coref_persons:\n",
    "                    linked_entity = coref_persons[governor_word]\n",
    "                elif dependent_word in coref_persons:\n",
    "                    linked_entity = coref_persons[dependent_word]\n",
    "\n",
    "                if linked_entity:\n",
    "                    if linked_entity not in entities:\n",
    "                        entities[linked_entity] = set()\n",
    "                    entities[linked_entity].add(governor_word)\n",
    "                    entities[linked_entity].add(dependent_word)\n",
    "\n",
    "    return entities\n",
    "\n",
    "\n",
    "\n",
    "def extract_entities_and_verbs(text):\n",
    "\n",
    "    annotated_text = nlp.annotate(text, properties={\n",
    "        'annotators': 'tokenize,ssplit,pos,lemma,ner', \n",
    "        'outputFormat': 'json'\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        annotated_json = json.loads(annotated_text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing the JSON response: {e}\")\n",
    "        return {}\n",
    "\n",
    "    entities = {}\n",
    "\n",
    "    for sentence in annotated_json.get('sentences', []):\n",
    "        sentence_verbs = set() \n",
    "        sentence_names = set() \n",
    "\n",
    "        for word in sentence.get('tokens', []):\n",
    "            word_text = word.get('word')\n",
    "            pos_tag = word.get('pos')\n",
    "            ner_tag = word.get('ner')\n",
    "\n",
    "            if ner_tag == 'PERSON':\n",
    "                sentence_names.add(word_text)\n",
    "\n",
    "            if pos_tag and pos_tag.startswith('VB'):  # verbs tags like VB-based\n",
    "                sentence_verbs.add(word_text)\n",
    "\n",
    "       \n",
    "        for name in sentence_names:\n",
    "            if name not in entities:\n",
    "                entities[name] = set()\n",
    "            \n",
    "            entities[name].update(sentence_verbs)\n",
    "        return entities\n",
    "        \n",
    "def retry_request(text, retries=3, delay=5):\n",
    "\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            annotated_text = nlp.annotate(text, properties={\n",
    "                'annotators': 'tokenize,ssplit,pos,ner,sentiment',\n",
    "                'outputFormat': 'json',\n",
    "                'timeout': 30000 \n",
    "            })\n",
    "            return json.loads(annotated_text)\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(delay) \n",
    "            else:\n",
    "                return None\n",
    "            \n",
    "def extract_entity_sentiments(text):\n",
    "    \n",
    "    annotated_json = retry_request(text)\n",
    "    if annotated_json is None:\n",
    "        print(\"Failed to process the text.\")\n",
    "        return {}, {}\n",
    "\n",
    "    entities_sentiments = {}\n",
    "    overall_sentiment_counts = {\"Good\": 0, \"Neutral\": 0, \"Bad\": 0}\n",
    "\n",
    "    for sentence in annotated_json.get('sentences', []):\n",
    "        sentiment = sentence.get('sentiment') \n",
    "        sentiment_category = None\n",
    "\n",
    "        if sentiment in ['Verypositive', 'Positive']:\n",
    "            sentiment_category = \"Good\"\n",
    "        elif sentiment in ['Neutral']:\n",
    "            sentiment_category = \"Neutral\"\n",
    "        elif sentiment in ['Negative', 'Verynegative']:\n",
    "            sentiment_category = \"Bad\"\n",
    "\n",
    "        if sentiment_category:\n",
    "            overall_sentiment_counts[sentiment_category] += 1\n",
    "\n",
    "        sentence_entities = {\n",
    "            token['word'] for token in sentence.get('tokens', [])\n",
    "            if token.get('ner') == 'PERSON'\n",
    "        }\n",
    "\n",
    "        for entity in sentence_entities:\n",
    "            if entity not in entities_sentiments:\n",
    "                entities_sentiments[entity] = {\"Good\": 0, \"Neutral\": 0, \"Bad\": 0}\n",
    "            entities_sentiments[entity][sentiment_category] += 1\n",
    "\n",
    "    return overall_sentiment_counts, entities_sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Structure:\n",
      "Columns: ['wiki_id', 'plot_summary']\n",
      "Delimiter: \t\n",
      "Encoding: utf-8\n",
      "21114814\tA miserly man cheats his wife one night. A series from misunderstandings ensue that will entirely change his life.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = r'C:\\Users\\valbi\\Desktop\\Ma3\\ADA\\Projet1\\ada-2024-project-spaghettisolution\\data\\raw_data\\plot_summaries.txt'\n",
    "\n",
    "\n",
    "file_structure = {\n",
    "    'columns': ['wiki_id', 'plot_summary'],\n",
    "    'delimiter': '\\t',\n",
    "    'encoding': 'utf-8'\n",
    "}\n",
    "\n",
    "# Print the structure of the extracted file\n",
    "print(\"File Structure:\")\n",
    "print(f\"Columns: {file_structure['columns']}\")\n",
    "print(f\"Delimiter: {file_structure['delimiter']}\")\n",
    "print(f\"Encoding: {file_structure['encoding']}\")\n",
    "\n",
    "# Open and read the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    content = file.readlines()\n",
    "    \n",
    "\n",
    "# Select 10 random films from the content\n",
    "random_films = random.sample(content, 5)\n",
    "print(random_films[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Film:\n",
      "33103584\tOpium smugglers work in Sydney. There is a car chase which ends in a crash, a cabaret which turns into a church, a yacht race in Sydney harbour, and 40 bathing beauties.\n",
      "\n",
      "\n",
      "Adjectives:\n",
      "\n",
      "Adjectives Related:\n",
      "\n",
      "Adjectives and verbs Coref:\n",
      "\n",
      "Adjectives and verbs CorefV2:\n",
      "\n",
      "Verbs:\n",
      "\n",
      "Sentiments:\n",
      "\n",
      "Film:\n",
      "21114814\tA miserly man cheats his wife one night. A series from misunderstandings ensue that will entirely change his life.\n",
      "\n",
      "\n",
      "Adjectives:\n",
      "\n",
      "Adjectives Related:\n",
      "\n",
      "Adjectives and verbs Coref:\n",
      "\n",
      "Adjectives and verbs CorefV2:\n",
      "\n",
      "Verbs:\n",
      "\n",
      "Sentiments:\n",
      "Attempt 1 failed: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "Film:\n",
      "8235569\tGood and Evil are two sides of a same coin. If good grows in strength so does evil. And there comes a point when one must overcome the other. Dr.Gayatri  is an Indian American paranormal researcher at University of California, researching the esoteric practices like voodoo, spirit possession, magic and healing powers. She seeks to find the hidden knowledge that goes into such practices, the knowledge that cannot be explained by science or logic. Her search for answers brings her with her team of fellow scientists from America to India. In India she comes across an uncommon man named Varun  who is gifted with special intuitive and healing powers which he claims to have developed through mediation. He can alter people's minds through his mental powers. He is a blend of Indian philosophy and modern culture, a master at martial arts and a devotee of Lord Hanuman who heals people by absorbing their pain, meditates, and does worshiping in day, while he works as a bouncer at a club at night. Gayatri is immediately flummoxed by Varun’s powers to take away pain and disease from people and cure them. He becomes the subject of her study. After a few experiments by Gayatri, Varun has an intuitive insight about the existence of a dark power that is hidden and evil. Many questions crop in his mind – like what is this dark force and what is its source. He knows that the force is linked to Ravana's Rudraksh, which is hidden away somewhere, unknown to the world. This is not a normal Rudraksh. It carries in its seed the powers that can transmute humans into new species. The bearer of this Rudraksh will have supernatural powers beyond imagination. In the language of science, it was a multi-dimensional hologram in the form of a seed. Meanwhile, Bhuria, a Rakshasa mentally communicates with Varun via his mind-space and offers Varun to share his power with Bhuria by becoming his brother, since either of them cannot utilize full power of the Rudraksha alone, but can do this with their powers combined. Varun, being a good person, straight-away refuses friendship with a rakshasha but Bhuria continues his attempts to join their powers and manipulate Varun. On the other side, Gayatri finds about a madman speaking some strange words which cause changes in people. Gayatri tests the effects of those sounds on a rat, and notices strange mutations and changes in functioning of the rat's body. Souzy, Gayatri's research assistant, hears those sounds directly, becomes possessed, starts working for Bhuria and tries to kill Gayatri, but Varun fights her and saves Gayatri, after which Souzy commits suicide by jumping from the top of a building. . Varun and Gayatri thus set out on a search to discover this Rudraksh, the reality of Bhuria and also find certain answers for Varun's own self. His search transforms into a perilous journey from the most rugged terrains of Himalayas to the mysterious ruins of the legendary King Ravana's palaces in Yala, Sri Lanka. He thus finds how Bhuria, a poor but wild and arrogant labor contractor in excavation team of the Rudraksha, transformed into a powerful Rakshasha & possessor of supernatural powers, that the words spoken by the madman were actually an ancient verse, a Rakshasha mantra, and that the real aim of Bhuria is to use the Rudraksha and Rakshasha mantra for spreading evil and hatred in the world, thus effectively restoring the rule of rakshashas once more. It thus, once more becomes a battle of good vs. evil, where either must overcome the other.\n",
      "\n",
      "\n",
      "Adjectives:\n",
      "Entity: Varun, Adjectives: intuitive, gifted, good, certain, full, possessed, uncommon, own, special\n",
      "Entity: Gayatri, Adjectives: intuitive, other, possessed, own, dark, few, certain, strange\n",
      "Entity: Rudraksh, Adjectives: certain, own, supernatural\n",
      "Entity: Bhuria, Adjectives: wild, arrogant, real, powerful, good, supernatural, full, poor, ancient\n",
      "Entity: Souzy, Adjectives: possessed\n",
      "Entity: Rakshasha, Adjectives: wild, arrogant, real, powerful, poor, ancient, supernatural\n",
      "\n",
      "Adjectives Related:\n",
      "Entity: Varun, Adjectives: \n",
      "Entity: Gayatri, Adjectives: \n",
      "Entity: Rudraksh, Adjectives: \n",
      "Entity: Bhuria, Adjectives: \n",
      "Entity: Souzy, Adjectives: \n",
      "Entity: Rakshasha, Adjectives: powerful\n",
      "\n",
      "Adjectives and verbs Coref:\n",
      "Entity: Bhuria, Adjectives: alter, knows, blend, becomes, communicates, continues, verse, finds, offers\n",
      "Entity: Varun, Adjectives: fights, saves, has, set, person, refuses\n",
      "Entity: Gayatri, Adjectives: hears, tries, starts, notices, set, tests, finds, commits\n",
      "\n",
      "Adjectives and verbs CorefV2:\n",
      "Entity: Bhuria, Adjectives: alter, knows, blend, becomes, communicates, continues, verse, finds, offers\n",
      "Entity: Varun, Adjectives: fights, saves, has, set, person, refuses\n",
      "Entity: Rudraksh, Adjectives: This, Rudraksh, normal\n",
      "Entity: Gayatri, Adjectives: hears, tries, starts, notices, set, tests, finds, commits\n",
      "Entity: Rakshasha, Adjectives: powerful\n",
      "\n",
      "Verbs:\n",
      "\n",
      "Sentiments:\n",
      "Entity: Varun, Sentiments: {'Good': 3, 'Neutral': 1, 'Bad': 2}\n",
      "Entity: Gayatri, Sentiments: {'Good': 2, 'Neutral': 1, 'Bad': 3}\n",
      "Entity: Rudraksh, Sentiments: {'Good': 2, 'Neutral': 0, 'Bad': 0}\n",
      "Entity: Bhuria, Sentiments: {'Good': 1, 'Neutral': 1, 'Bad': 1}\n",
      "Entity: Souzy, Sentiments: {'Good': 0, 'Neutral': 0, 'Bad': 1}\n",
      "Entity: Rakshasha, Sentiments: {'Good': 0, 'Neutral': 0, 'Bad': 1}\n",
      "\n",
      "Film:\n",
      "2676497\tThe film is a romantic melodramaabout two childhood friends who grow up to be soldiers in Austria. One of the friends, Leo,  becomes infatuated with Felicitas , who turns out to be the wife of a powerful count . The count calls Leo out for a duel of honor, but insists that it be done under the false pretense that the quarrel was due to angry words exchanged between the two at a card game in order to protect the count's reputation. Leo kills the count in the duel, but then is punished by the military, being sent away to Africa for five years. Due to Ulrich's intervention, Leo only serves three years before being recalled home. He return journey focuses on his dream of being reunited with Felicitas. Before he left for Africa, Leo had ask Ulrich  to take care of Felicitas' needs while he was away, but Ulrich — unaware that his friend is in love with Felicitas — falls in love with her himself and marries her. Upon his return, Leo finds himself torn between temptation for Felicitas — which the young woman encourages — and his friendship for Ulrich. Condemned by a local pastor for continuing to associate with Felicitas, Leo eventually loses control of his emotions. Felicitas plays Leo for a fool. He tries to kill her by choking her, leading to a climactic duel between the two boyhood friends. While racing to stop the duel, Felicitas falls through a layer of thin ice and drowns. Meanwhile, the friends reconcile, realizing that their friendship is more important than Felicitas.\n",
      "\n",
      "\n",
      "Adjectives:\n",
      "Entity: Leo, Adjectives: infatuated, unaware, local, angry, due, young, powerful, false\n",
      "Entity: Felicitas, Adjectives: infatuated, unaware, local, thin, important, powerful\n",
      "Entity: Ulrich, Adjectives: young, unaware\n",
      "\n",
      "Adjectives Related:\n",
      "Entity: Leo, Adjectives: \n",
      "Entity: Felicitas, Adjectives: \n",
      "Entity: Ulrich, Adjectives: \n",
      "\n",
      "Adjectives and verbs Coref:\n",
      "Entity: Felicitas, Adjectives: plays, turns, falls, choking\n",
      "Entity: Leo, Adjectives: tries, ask, serves, unaware, return, loses, kills, finds, torn, was, left\n",
      "\n",
      "Adjectives and verbs CorefV2:\n",
      "Entity: Felicitas, Adjectives: plays, turns, falls, choking\n",
      "Entity: Leo, Adjectives: tries, ask, serves, unaware, return, loses, kills, finds, torn, was, left\n",
      "\n",
      "Verbs:\n",
      "\n",
      "Sentiments:\n",
      "Entity: Leo, Sentiments: {'Good': 2, 'Neutral': 3, 'Bad': 3}\n",
      "Entity: Felicitas, Sentiments: {'Good': 4, 'Neutral': 0, 'Bad': 3}\n",
      "Entity: Ulrich, Sentiments: {'Good': 1, 'Neutral': 2, 'Bad': 0}\n",
      "\n",
      "Film:\n",
      "30574080\tThe film starts with Abbott Fahai and his assistant Neng Ren heading towards a snow blizzard through a magical door. An ice harpy appears at the top of the mountains and turns the impetuous Neng Ren into an ice statue. She then reveals her past and reasons to kill all men. Unable to persuade the ice harpy to turn over a new leaf, Fahai is forced to fight the ice harpy. The battle ends with Fahai capturing the ice harpy using a demon trapper, which releases Neng Ren from ice. Neng Ren is then tasked to confine the ice harpy at Lei Feng Pagoda, and the master and assistant head back to the door which disappears after closing behind them. At Lei Feng Pagoda, Neng Ren transfers the ice harpy from the demon trapper into the magic circle, which holds other trapped demons in it. On the other side of the mountain, two snake demons  are playing around, enjoying their time when they spot a physician, Xu Xian, picking herbs at the foot of the mountain with his friends. Qingqing, being a playful snake, scares Xu Xian causing him to fall into the lake below. Susu, being the gentler snake, assumes human form and kisses Xu Xian which allows Vital Essence to flow from her into his body thus saving him. Soon, Xu Xian wakes up and tells his friends about being kissed by a beautiful girl, which only makes them laugh. After finding a victim of a bat demon, Fahai and Neng Ren leave the temple immediately to subdue the bat demon to avoid more casualties. Xu Xian came across them and offers a boat ride to the city. Susu starts thinking about the day she kissed Xu Xian and decides to head to the city to find Xu Xian. Meanwhile, while Qingqing is exploring the city, she came across Neng Ren and decided to help him subdue the bat demon by revealing its location. Neng Ren defeats the bat demon's cohorts, but is unable to subdue the bat demon king who bites him. Though he is subsequently saved by Fahai, Neng Ren starts turning into a bat demon himself the next day and decides to run away. In the meanwhile, after a series of pranks, Xu Xian recognizes Susu and they spend the night together, which is rather unfortunate for Xu Xian because he does not know that he was making love to a snake in a human form. Neng Ren is found by Quinqing and the two befriend each other. They realize that Neng Ren, despite becoming a bat demon, still has all his human taste for human food, and most of his human qualities. Meanwhile Xu Xian and Susu wed. Shortly thereafter Fahai finds Xu Xian and after seeing a mysterious substance in his medicines he gives Xu Xian a spirit blade. Susu is pursued by Fahai, who tells her to leave Xu Xian. She doesn't, which causes Fahai and his disciples to invade her and Xu Xian's cottage. Susu fights the battle in her snake form, but is stabbed by Xu Xian unaware of her true identity. Susu escapes...while Xu Xian decides that he must save her. Helped by Susu's friend, a mouse, Xu Xian manages to retrieve a root kept inside the Lei Feng Pagoda that could save Susu, but is possessed by demons as a result of this. Fahai and the other monks capture Xu Xian and prepare to cast spells to banish the demons from his body. Susu recovers and she goes to find Xu Xian along with Quinqing. They are confronted by Fahai, who tries to explain to them that the spell should not be broken before it is complete. But Susu misunderstands his intentions and the two sisters start battling Fahai. After countless wounds Fahai lies back exhausted. As he looks around he sees Neng Ren helping to save his former colleagues, the monks of the temple who were trying to complete the spell to release Xu Xian from the demons. He looks up at the sky and questions whether he was right to have been a demon hunter all his life. Susu releases Xu Xian from the spell after which Xu Xian does not have any memory of Susu. Susu blames this on Fahai, after which they have one last battle. Fahai manages to trap Susu in the temple of Lei Feng Pagoda. At this point, Susu repents and asks to see Xu Xian just one last time. Simultaneously, Fahai gets the answer to his question and understands what he must do. Filled with the divine spirit, he lifts up the pagoda to allow Susu's last wish to come true. After a brief reunion with Xu Xian, she tells him of her story of having meditated for a thousand years before she met him. She tells him that it was all worth less than a moment with him. She kisses him, causing him to remember everything. As the pair go to kiss one last time Susu is sucked back into the temple, leaving Xu Xian chasing her as both cry and reach out for each other. Qingqing, watching all this from a distance with Neng Ren, tells him that she doesn't want to love anyone as her sister loved Xu Xian, and leaves saying that he will never be a true bat demon anyway. After this, we see Xu Xian picking herbs around the temple and inside Susu has returned to her true form as a white snake trapped inside the temple. Fahai is seen walking the mountainside when suddenly Neng Ren  appears alongside him. Throwing him an apple to eat Fahai tells him that his new look suits him, and they continue on the journey together again.\n",
      "\n",
      "\n",
      "Adjectives:\n",
      "Entity: Abbott, Adjectives: magical\n",
      "Entity: Ren, Adjectives: former, other, assistant, true, most, impetuous, trapped, human, magical, unable, next, more\n",
      "Entity: Fahai, Adjectives: mysterious, other, new, complete, Unable, magical, last, next, more\n",
      "Entity: Neng, Adjectives: former, other, assistant, true, most, impetuous, trapped, human, magical, unable, next, more\n",
      "Entity: Xian, Adjectives: mysterious, former, playful, unaware, true, other, brief, human, last, beautiful, white, unfortunate\n",
      "Entity: Xu, Adjectives: mysterious, former, playful, unaware, true, other, brief, human, last, beautiful, white, unfortunate\n",
      "Entity: Qingqing, Adjectives: playful, true\n",
      "Entity: Susu, Adjectives: Vital, unaware, true, other, human, last, divine, white, unfortunate, gentler\n",
      "Entity: Quinqing, Adjectives: other\n",
      "\n",
      "Adjectives Related:\n",
      "Entity: Abbott, Adjectives: \n",
      "Entity: Ren, Adjectives: impetuous\n",
      "Entity: Fahai, Adjectives: battling\n",
      "Entity: Neng, Adjectives: \n",
      "Entity: Xian, Adjectives: \n",
      "Entity: Xu, Adjectives: \n",
      "Entity: Qingqing, Adjectives: \n",
      "Entity: Susu, Adjectives: \n",
      "Entity: Quinqing, Adjectives: \n",
      "\n",
      "Adjectives and verbs Coref:\n",
      "Entity: Fahai, Adjectives: do, subdue, tells, causes, capturing, making, reveals, know, understands, manages, sees, demon, save, seeing, gets, lies, looks, lifts, gives, right, kisses, battling, finds\n",
      "Entity: Qingqing, Adjectives: exploring, tells, scares\n",
      "Entity: Susu, Adjectives: goes, tells, starts, decided, fights, misunderstands, blames, releases, want, escapes, met, kissed, looks, leaves, kisses, came, recovers, decides, assumes\n",
      "\n",
      "Adjectives and verbs CorefV2:\n",
      "Entity: Ren, Adjectives: defeats, starts, has, impetuous, appears, unable, transfers\n",
      "Entity: Fahai, Adjectives: do, subdue, tells, causes, capturing, making, reveals, know, understands, manages, sees, demon, save, seeing, gets, lies, looks, lifts, gives, right, kisses, battling, finds\n",
      "Entity: Qingqing, Adjectives: exploring, tells, scares\n",
      "Entity: Xian, Adjectives: recognizes, gives, came, wakes, decides, causing, Xian, tells, reach, picking, chasing, have, offers\n",
      "Entity: Susu, Adjectives: goes, tells, starts, decided, fights, misunderstands, blames, releases, want, escapes, met, kissed, looks, leaves, kisses, came, recovers, decides, assumes\n",
      "\n",
      "Verbs:\n",
      "Entity: Abbott, Verbs: starts, heading\n",
      "Entity: Ren, Verbs: starts, heading\n",
      "Entity: Fahai, Verbs: starts, heading\n",
      "Entity: Neng, Verbs: starts, heading\n",
      "\n",
      "Sentiments:\n",
      "Entity: Abbott, Sentiments: {'Good': 1, 'Neutral': 0, 'Bad': 0}\n",
      "Entity: Ren, Sentiments: {'Good': 4, 'Neutral': 6, 'Bad': 4}\n",
      "Entity: Fahai, Sentiments: {'Good': 5, 'Neutral': 3, 'Bad': 7}\n",
      "Entity: Neng, Sentiments: {'Good': 4, 'Neutral': 6, 'Bad': 4}\n",
      "Entity: Xian, Sentiments: {'Good': 4, 'Neutral': 8, 'Bad': 9}\n",
      "Entity: Xu, Sentiments: {'Good': 4, 'Neutral': 8, 'Bad': 9}\n",
      "Entity: Qingqing, Sentiments: {'Good': 1, 'Neutral': 1, 'Bad': 1}\n",
      "Entity: Susu, Sentiments: {'Good': 3, 'Neutral': 6, 'Bad': 8}\n",
      "Entity: Quinqing, Sentiments: {'Good': 0, 'Neutral': 2, 'Bad': 0}\n"
     ]
    }
   ],
   "source": [
    "nlp = StanfordCoreNLP(r'stanford-corenlp-4.5.7\\stanford-corenlp-4.5.7')\n",
    "\n",
    "for film in random_films:\n",
    "    entities_adjectives = extract_entities_and_adjectives(film)\n",
    "    entities_adjectives_related = extract_entities_and_adjectives_related(film)\n",
    "    entities_adjectives_coref = extract_entities_and_adjectives_and_verbs_with_coref(film)\n",
    "    entities_adjectives_corefV2 = extract_entities_and_adjectives_with_corefV2(film)\n",
    "    entities_verbs = extract_entities_and_verbs(film)\n",
    "    overall_sentiment_counts, entities_sentiments = extract_entity_sentiments(film)\n",
    "    print(\"\\nFilm:\")\n",
    "    print(film)\n",
    "    \n",
    "    print(\"\\nAdjectives:\")\n",
    "    for entity, adj_list in entities_adjectives.items():\n",
    "        print(f\"Entity: {entity}, Adjectives: {', '.join(adj_list)}\")\n",
    "\n",
    "    print(\"\\nAdjectives Related:\")\n",
    "    for entity, adj_list in entities_adjectives_related.items():\n",
    "        print(f\"Entity: {entity}, Adjectives: {', '.join(adj_list)}\")\n",
    "\n",
    "    print(\"\\nAdjectives and verbs Coref:\")\n",
    "    for entity, adj_list in entities_adjectives_coref.items():\n",
    "        print(f\"Entity: {entity}, Adjectives: {', '.join(adj_list)}\")\n",
    "\n",
    "    print(\"\\nAdjectives and verbs CorefV2:\")\n",
    "    for entity, adj_list in entities_adjectives_corefV2.items():\n",
    "        print(f\"Entity: {entity}, Adjectives: {', '.join(adj_list)}\")\n",
    "\n",
    "    print(\"\\nVerbs:\")\n",
    "    for entity, verb_list in entities_verbs.items():\n",
    "        print(f\"Entity: {entity}, Verbs: {', '.join(verb_list)}\")\n",
    "    \n",
    "    print(\"\\nSentiments:\")\n",
    "    for entity, sentiments in entities_sentiments.items():\n",
    "        print(f\"Entity: {entity}, Sentiments: {sentiments}\")\n",
    "        \n",
    "nlp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2676497\tThe film is a romantic melodramaabout two childhood friends who grow up to be soldiers in Austria. One of the friends, Leo,  becomes infatuated with Felicitas , who turns out to be the wife of a powerful count . The count calls Leo out for a duel of honor, but insists that it be done under the false pretense that the quarrel was due to angry words exchanged between the two at a card game in order to protect the count's reputation. Leo kills the count in the duel, but then is punished by the military, being sent away to Africa for five years. Due to Ulrich's intervention, Leo only serves three years before being recalled home. He return journey focuses on his dream of being reunited with Felicitas. Before he left for Africa, Leo had ask Ulrich  to take care of Felicitas' needs while he was away, but Ulrich — unaware that his friend is in love with Felicitas — falls in love with her himself and marries her. Upon his return, Leo finds himself torn between temptation for Felicitas — which the young woman encourages — and his friendship for Ulrich. Condemned by a local pastor for continuing to associate with Felicitas, Leo eventually loses control of his emotions. Felicitas plays Leo for a fool. He tries to kill her by choking her, leading to a climactic duel between the two boyhood friends. While racing to stop the duel, Felicitas falls through a layer of thin ice and drowns. Meanwhile, the friends reconcile, realizing that their friendship is more important than Felicitas.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(random_films[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
